{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emAUeLserWhf"
   },
   "source": [
    "**Forecast of power 3 hours ahead based on LSTM with knowledge of wind speed - with use of 7 days slices**\n",
    "\n",
    "As a first step, an LSTM network is implemented considering only the power time series. The results can be compared with those of the AR(4) model fitted to the data in Matlab: 95% confidence intervals:\n",
    "\n",
    "*   1h ahead: [-3.17:3.17]\n",
    "*   2h ahead: [-4.73:4.73]\n",
    "*   3h ahead: [-5.76:5.76]\n",
    "\n",
    "And the LSTM network with slices:\n",
    "\n",
    "*   1h ahead: [-3.12:3.12]\n",
    "*   2h ahead: [-4.67:4.67]\n",
    "*   3h ahead: [-5.72:5.72]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1634931924436,
     "user": {
      "displayName": "Boris Guillerey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbROKUXNp2pGi5Vq913fYXBXAeX8gG7PPboJMNgg=s64",
      "userId": "07084368608255328810"
     },
     "user_tz": -120
    },
    "id": "2P9gAZGSs4P5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import statistics as stat\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1634931924745,
     "user": {
      "displayName": "Boris Guillerey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbROKUXNp2pGi5Vq913fYXBXAeX8gG7PPboJMNgg=s64",
      "userId": "07084368608255328810"
     },
     "user_tz": -120
    },
    "id": "o-MWQJtWUhKI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1634931924746,
     "user": {
      "displayName": "Boris Guillerey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbROKUXNp2pGi5Vq913fYXBXAeX8gG7PPboJMNgg=s64",
      "userId": "07084368608255328810"
     },
     "user_tz": -120
    },
    "id": "3w8xacq6sY78"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\cex4WindDataInterpolated.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1d3e70dfbaa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the data and extract only the power time series and time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\cex4WindDataInterpolated.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\cex4WindDataInterpolated.csv'"
     ]
    }
   ],
   "source": [
    "# Load the data and extract only the power time series and time\n",
    "file = '\\cex4WindDataInterpolated.csv'\n",
    "data = pd.read_csv(file)\n",
    "t = data.iloc[:,0].values\n",
    "p = data.iloc[:,2].values\n",
    "ws1 = data.iloc[:,3].values\n",
    "ws2 = data.iloc[:,6].values\n",
    "ws3 = data.iloc[:,9].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1634931924746,
     "user": {
      "displayName": "Boris Guillerey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbROKUXNp2pGi5Vq913fYXBXAeX8gG7PPboJMNgg=s64",
      "userId": "07084368608255328810"
     },
     "user_tz": -120
    },
    "id": "X598gmnBtLzB"
   },
   "outputs": [],
   "source": [
    "# Normalize the data except wind direction which will be one hot encoded\n",
    "p_mean = np.nanmean(p)\n",
    "p_std = np.nanstd(p)\n",
    "ws_mean = np.nanmean(ws1)\n",
    "ws_std = np.nanstd(ws1)\n",
    "\n",
    "p = (p-p_mean)/p_std\n",
    "ws1 = (ws1-ws_mean)/ws_std\n",
    "ws2 = (ws2-ws_mean)/ws_std\n",
    "ws3 = (ws3-ws_mean)/ws_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1634931925250,
     "user": {
      "displayName": "Boris Guillerey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbROKUXNp2pGi5Vq913fYXBXAeX8gG7PPboJMNgg=s64",
      "userId": "07084368608255328810"
     },
     "user_tz": -120
    },
    "id": "BMnS5eeJI9U8"
   },
   "outputs": [],
   "source": [
    "# Loop to keep sequences of valid power and wind speed\n",
    "p_valid, ws1_valid, ws2_valid, ws3_valid = [],[],[],[]\n",
    "current_seq_p, current_seq_ws1, current_seq_ws2 , current_seq_ws3  = [],[],[],[]\n",
    "\n",
    "nan = 1             # 1 if former value is nan\n",
    "\n",
    "for i in range(len(p)):\n",
    "\n",
    "  # Check if current value is nan\n",
    "  if np.isnan(p[i]) or np.isnan(ws1[i]):\n",
    "    # If former value not nan, store former sequence and create a new one \n",
    "    if nan == 0:\n",
    "      p_valid.append(current_seq_p)\n",
    "      ws1_valid.append(current_seq_ws1)\n",
    "      ws2_valid.append(current_seq_ws2)\n",
    "      ws3_valid.append(current_seq_ws3)\n",
    "      current_seq_p, current_seq_ws1, current_seq_ws2 , current_seq_ws3  = [],[],[],[]\n",
    "    nan = 1\n",
    "\n",
    "  # Else, store the value and state it is not nan\n",
    "  else:\n",
    "    current_seq_p.append([p[i]])\n",
    "    current_seq_ws1.append([ws1[i]])\n",
    "    current_seq_ws2.append([ws2[i]])\n",
    "    current_seq_ws3.append([ws3[i]])\n",
    "    nan = 0\n",
    "\n",
    "p_valid.append(current_seq_p)\n",
    "ws1_valid.append(current_seq_ws1)\n",
    "ws2_valid.append(current_seq_ws2)\n",
    "ws3_valid.append(current_seq_ws3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1634931925497,
     "user": {
      "displayName": "Boris Guillerey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbROKUXNp2pGi5Vq913fYXBXAeX8gG7PPboJMNgg=s64",
      "userId": "07084368608255328810"
     },
     "user_tz": -120
    },
    "id": "Cw_hS6vctl9s"
   },
   "outputs": [],
   "source": [
    "# Define slices of 168h power inputs and corresponding targets one 1h ahead\n",
    "# Also define forecasts of wind speed\n",
    "p_inputs, p_targets, p_targets2h, p_targets3h = [],[],[],[]\n",
    "ws1_forecast, ws2_forecast, ws3_forecast = [],[],[]\n",
    "\n",
    "for seq in range(len(p_valid)):\n",
    "  for i in range(len(p_valid[seq])-170):\n",
    "    p_inputs.append(p_valid[seq][i:i+168])\n",
    "    p_targets.append(p_valid[seq][i+168])\n",
    "    p_targets2h.append(p_valid[seq][i+169])\n",
    "    p_targets3h.append(p_valid[seq][i+170])\n",
    "    ws1_forecast.append(ws1_valid[seq][i+168])\n",
    "    ws2_forecast.append(ws2_valid[seq][i+169])\n",
    "    ws3_forecast.append(ws3_valid[seq][i+170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 373,
     "status": "ok",
     "timestamp": 1634931925864,
     "user": {
      "displayName": "Boris Guillerey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbROKUXNp2pGi5Vq913fYXBXAeX8gG7PPboJMNgg=s64",
      "userId": "07084368608255328810"
     },
     "user_tz": -120
    },
    "id": "50kV30jDZDOi"
   },
   "outputs": [],
   "source": [
    "# Shuffle the inputs and targets\n",
    "random.seed(10)\n",
    "l = list(zip(p_inputs,p_targets,p_targets2h,p_targets3h,ws1_forecast,ws2_forecast,ws3_forecast))\n",
    "random.shuffle(l)\n",
    "p_inputs,p_targets,p_targets2h,p_targets3h,ws1_forecast,ws2_forecast,ws3_forecast = zip(*l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1634931926097,
     "user": {
      "displayName": "Boris Guillerey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbROKUXNp2pGi5Vq913fYXBXAeX8gG7PPboJMNgg=s64",
      "userId": "07084368608255328810"
     },
     "user_tz": -120
    },
    "id": "CfOhAEu0xVTr",
    "outputId": "4bb7ccde-4bc1-4f7f-aa84-04ba5ffc5b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyRecurrentNet(\n",
      "  (lstm): LSTM(1, 128)\n",
      "  (ffnn_forecast1): Linear(in_features=1, out_features=512, bias=False)\n",
      "  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (ffnn_forecast2): Linear(in_features=512, out_features=512, bias=False)\n",
      "  (batchnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l_out1): Linear(in_features=640, out_features=64, bias=False)\n",
      "  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l_out2): Linear(in_features=64, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define an LSTM network\n",
    "\n",
    "class MyRecurrentNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyRecurrentNet, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size =1,hidden_size=128, batch_first = False)        \n",
    "        \n",
    "        self.ffnn_forecast1 = nn.Linear(in_features = 1, out_features = 512, bias = False)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.ffnn_forecast2 = nn.Linear(in_features = 512, out_features = 512, bias = False)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        # Output layer\n",
    "        self.l_out1 = nn.Linear(in_features=512+128,\n",
    "                            out_features=64,\n",
    "                            bias=False)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        self.l_out2 = nn.Linear(in_features=64,\n",
    "                            out_features=1,\n",
    "                            bias=False)\n",
    "        \n",
    "    def forward(self, p_past, ws_forecast):\n",
    "\n",
    "        # RNN returns output\n",
    "        x_rnn, (h, c) = self.lstm(p_past)\n",
    "        \n",
    "        # FNN on the wind speed forecast\n",
    "        x_ffnn = self.ffnn_forecast1(ws_forecast)\n",
    "        x_ffnn = self.batchnorm1(x_ffnn)\n",
    "        x_ffnn = elu(x_ffnn)\n",
    "        x_ffnn = self.ffnn_forecast2(x_ffnn)\n",
    "        x_ffnn = self.batchnorm2(x_ffnn)\n",
    "        x_ffnn = elu(x_ffnn)\n",
    "\n",
    "        # Output layer on the concatenate last rnn hidden state and ffnn result\n",
    "        x = torch.cat((x_rnn[-1], x_ffnn), 1)  # Concatenate on dimension 1, 0 being the batch samples, 1 being the units\n",
    "        x = elu(self.l_out1(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.l_out2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "net = MyRecurrentNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1634931926098,
     "user": {
      "displayName": "Boris Guillerey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbROKUXNp2pGi5Vq913fYXBXAeX8gG7PPboJMNgg=s64",
      "userId": "07084368608255328810"
     },
     "user_tz": -120
    },
    "id": "-KSR0vFRFTn_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1634931926098,
     "user": {
      "displayName": "Boris Guillerey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbROKUXNp2pGi5Vq913fYXBXAeX8gG7PPboJMNgg=s64",
      "userId": "07084368608255328810"
     },
     "user_tz": -120
    },
    "id": "h-M5ODoozyR-",
    "outputId": "eb5b8c6f-a3f8-49be-ecbb-208cce6d1cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0622],\n",
       "        [ 0.0622]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test of a dummy input of two sequences\n",
    "dummy = torch.tensor(list([\n",
    "                                [[1.0],[2.0],[3.0]],\n",
    "                                [[4.0],[5.0],[6.0]]\n",
    "                    ])).float()\n",
    "dummy = torch.swapaxes(dummy,0,1) # The network uses the format (Seq, Batch, Features)\n",
    "forecast = torch.tensor([[1.0],[2.0]]).float()\n",
    "net(dummy,forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1634931926099,
     "user": {
      "displayName": "Boris Guillerey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbROKUXNp2pGi5Vq913fYXBXAeX8gG7PPboJMNgg=s64",
      "userId": "07084368608255328810"
     },
     "user_tz": -120
    },
    "id": "kYXiSNGTRHLj",
    "outputId": "9cd1dc5b-ac26-4597-a966-bc190bfc3659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2925],\n",
       "        [-0.2925]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the untrained network on two first sequences\n",
    "net(torch.swapaxes(torch.Tensor([p_inputs[0],p_inputs[1]]),0,1),torch.Tensor([ws1_forecast[0],ws1_forecast[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1634931926099,
     "user": {
      "displayName": "Boris Guillerey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbROKUXNp2pGi5Vq913fYXBXAeX8gG7PPboJMNgg=s64",
      "userId": "07084368608255328810"
     },
     "user_tz": -120
    },
    "id": "pK-WIrQw3oXy"
   },
   "outputs": [],
   "source": [
    "# Initialize the network\n",
    "net = MyRecurrentNet()\n",
    "# Convert to cuda if GPU available\n",
    "if torch.cuda.is_available():\n",
    "    print('##converting network to cuda-enabled')\n",
    "    net.cuda()\n",
    "\n",
    "# Define loss function and train parameters\n",
    "criterion = nn.MSELoss(reduction='sum')    # Sum the squares but not perform the mean\n",
    "\n",
    "# Adam gradient descent with learning rate decay\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "decayRate = 0.999\n",
    "decay_scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "# Length of the training and batches\n",
    "epochs = 40\n",
    "batch_size = 64\n",
    "num_batch = len(p_inputs)//batch_size\n",
    "\n",
    "# Function to get the batch\n",
    "get_batch = lambda i, size: range(i * size, (i + 1) * size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwtnB57XBcfC",
    "outputId": "9ebc6543-b6b3-4355-8ef5-1a28002f6283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training RMSE: 1.96, CI: [-3.85:3.85]\n",
      "Epoch 2, training RMSE: 1.79, CI: [-3.51:3.51]\n",
      "Epoch 3, training RMSE: 1.78, CI: [-3.49:3.49]\n",
      "Epoch 4, training RMSE: 1.76, CI: [-3.44:3.44]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# Track loss\n",
    "training_RMSE = []\n",
    "\n",
    "# Loop over epochs\n",
    "for i in range(epochs):\n",
    "\n",
    "    epoch_training_loss = 0\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    # For each sequence in training set\n",
    "    for b in range(num_batch):\n",
    "\n",
    "      batch_index = get_batch(b,batch_size)\n",
    "                 \n",
    "      # Convert to tensor and swap axes of inputs to get (seq, batch, features)\n",
    "      inputs_past = torch.swapaxes(torch.Tensor(p_inputs)[batch_index],0,1)\n",
    "      inputs_forecast = torch.Tensor(ws1_forecast)[batch_index]\n",
    "      targets = torch.Tensor(p_targets)[batch_index]\n",
    "\n",
    "      # Convert to cuda to run on GPU\n",
    "      if torch.cuda.is_available():\n",
    "            inputs_past = Variable(inputs_past.cuda())\n",
    "            inputs_forecast = Variable(inputs_forecast.cuda())\n",
    "            targets = Variable(targets.cuda())\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = net(inputs_past,inputs_forecast)\n",
    "          \n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, targets)\n",
    "          \n",
    "      # Backward pass\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "          \n",
    "      # Update loss\n",
    "      if torch.cuda.is_available():\n",
    "        epoch_training_loss += loss.cpu().detach().numpy()\n",
    "      else:\n",
    "        epoch_training_loss += loss.detach().numpy()\n",
    "    \n",
    "    # Save loss for plot\n",
    "    epoch_RMSE = np.sqrt(epoch_training_loss/(num_batch*batch_size))\n",
    "    training_RMSE.append(epoch_RMSE*p_std) # Removing normalization to store RMSE and compute CI\n",
    "\n",
    "    # Compute confidence interval\n",
    "    CI = [norm.ppf(0.025)*training_RMSE[-1],norm.ppf(0.975)*training_RMSE[-1]]\n",
    "\n",
    "    # Print loss every 10 epochs\n",
    "    if i % 1 == 0:\n",
    "        print('Epoch %d, training RMSE: %.2f, CI: [%.2f:%.2f]' % (i+1,training_RMSE[-1],CI[0],CI[1]))\n",
    "\n",
    "    # Apply learning rate decay\n",
    "    decay_scheduler.step()\n",
    "\n",
    "# Plot training loss\n",
    "epoch = np.arange(len(training_RMSE))\n",
    "plt.figure()\n",
    "plt.plot(epoch, training_RMSE, 'r')\n",
    "plt.xlabel('Epoch'), plt.ylabel('Training RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjE83nCjCgO2"
   },
   "outputs": [],
   "source": [
    "# Back on CPU\n",
    "if torch.cuda.is_available():\n",
    "  net.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oevXpCKVfHPF"
   },
   "outputs": [],
   "source": [
    "# Plot the learnt power curve for different past sequences\n",
    "power = []\n",
    "v = []\n",
    "for i in range(40):\n",
    "  v.append(i)\n",
    " # net(torch.swapaxes(torch.Tensor([p_inputs[0],p_inputs[1]]),0,1),torch.Tensor([ws1_forecast[0],ws1_forecast[1]]))\n",
    "  power.append([net(torch.swapaxes(torch.Tensor([p_inputs[4]]),0,1),\n",
    "                    torch.Tensor([[(i-ws_mean)/ws_std]])).detach().numpy(),\n",
    "                net(torch.swapaxes(torch.Tensor([p_inputs[1]]),0,1),\n",
    "                    torch.Tensor([[(i-ws_mean)/ws_std]])).detach().numpy(),\n",
    "                net(torch.swapaxes(torch.Tensor([p_inputs[2]]),0,1),\n",
    "                    torch.Tensor([[(i-ws_mean)/ws_std]])).detach().numpy(),\n",
    "                net(torch.swapaxes(torch.Tensor([p_inputs[3]]),0,1),\n",
    "                    torch.Tensor([[(i-ws_mean)/ws_std]])).detach().numpy(),\n",
    "                net(torch.swapaxes(torch.Tensor([p_inputs[5]]),0,1),\n",
    "                    torch.Tensor([[(i-ws_mean)/ws_std]])).detach().numpy()])\n",
    "\n",
    "power = (np.squeeze(np.swapaxes(power,0,1),(2,3))*p_std)+p_mean\n",
    "\n",
    "former_power = [p_inputs[4][-1],p_inputs[1][-1],p_inputs[2][-1],p_inputs[3][-1],p_inputs[5][-1]]\n",
    "\n",
    "for i in range(5):\n",
    "  plt.plot(v,power[i], label='$p_{n-1}$ = %.2f MW' %(p_mean+p_std*former_power[i][0]))\n",
    "plt.xlabel('Wind speed [m/s]')\n",
    "plt.ylabel('Power [MW]')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBQwRy9vKTMJ"
   },
   "source": [
    "We see that independently of the wind speed, the network learnt from past sequences. If the former power was low, whatever high the forecasted wind speed is, the forecasted power will still be limited. This is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oF5yKg3ovBQb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IojzG9kMY1Y3"
   },
   "outputs": [],
   "source": [
    "# Forecasting 1, 2 and 3 hours ahead\n",
    "\n",
    "net.eval()\n",
    "\n",
    "# Store predictions and errors\n",
    "pred_1h = []\n",
    "err_1h = []\n",
    "pred_2h = []\n",
    "err_2h = []\n",
    "pred_3h = []\n",
    "err_3h = []\n",
    "\n",
    "# Loop over the sequences of valid data and ws forecast\n",
    "for seq in range(len(p_inputs)-2):\n",
    "\n",
    "    # Define past value for the 1h forecast\n",
    "    past = p_inputs[seq]\n",
    "    ws_forecast = ws1_forecast[seq]\n",
    "    \n",
    "    # Take output of first and only sequence, last value\n",
    "    pred_1h.append(net(torch.swapaxes(torch.Tensor([past]),0,1),torch.Tensor([ws_forecast])).item())\n",
    "    err_1h.append(pred_1h[-1]-p_targets[seq][0])\n",
    "\n",
    "    # Repeat with prediction 2 hours ahead actualizing first the past values\n",
    "    past.append([pred_1h[-1]])\n",
    "    ws_forecast = ws2_forecast[seq]   #Take the forecast for 2h ahead made at least 2h before (ws2)\n",
    "    pred_2h.append(net(torch.swapaxes(torch.Tensor([past]),0,1),torch.Tensor([ws_forecast])).item())\n",
    "    err_2h.append(pred_2h[-1]-p_targets2h[seq][0])\n",
    "\n",
    "    # Repeat with prediction 3 hours ahead\n",
    "    past.append([pred_2h[-1]])\n",
    "    ws_forecast = ws3_forecast[seq]\n",
    "    pred_3h.append(net(torch.swapaxes(torch.Tensor([past]),0,1),torch.Tensor([ws_forecast])).item())\n",
    "    err_3h.append(pred_3h[-1]-p_targets3h[seq][0])\n",
    "\n",
    "    if seq % 1000 == 0:\n",
    "      print('progress %.2f %%, RMSE 1h: %.2f, RMSE 2h: %.2f, RMSE 3h: %.2f'\n",
    "           % (100*(seq+1)/(len(p_inputs)-2),\n",
    "            p_std*np.sqrt(stat.mean(err_1h[n]**2 for n in range(len(err_1h)))),\n",
    "            p_std*np.sqrt(stat.mean(err_2h[n]**2 for n in range(len(err_2h)))), \n",
    "            p_std*np.sqrt(stat.mean(err_3h[n]**2 for n in range(len(err_3h)))))\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "an1NIEcvaw03"
   },
   "outputs": [],
   "source": [
    "# Estimation of confidence intervals:\n",
    "RMSE_1h = np.sqrt(stat.mean((p_std*err_1h[n])**2 for n in range(len(err_1h))))\n",
    "RMSE_2h = np.sqrt(stat.mean((p_std*err_2h[n])**2 for n in range(len(err_2h))))\n",
    "RMSE_3h = np.sqrt(stat.mean((p_std*err_3h[n])**2 for n in range(len(err_3h))))\n",
    "CI_1h = [norm.ppf(0.025)*RMSE_1h,norm.ppf(0.975)*RMSE_1h]\n",
    "CI_2h = [norm.ppf(0.025)*RMSE_2h,norm.ppf(0.975)*RMSE_2h]\n",
    "CI_3h = [norm.ppf(0.025)*RMSE_3h,norm.ppf(0.975)*RMSE_3h]\n",
    "print(f'Confidence interval 1h: {CI_1h}')\n",
    "print(f'Confidence interval 2h: {CI_2h}')\n",
    "print(f'Confidence interval 3h: {CI_3h}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XzmB_r4UCgKj"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(net.state_dict(),\n",
    "           '/content/drive/MyDrive/Colab Notebooks/Time series/LSTM_Klim/LSTM_power_ws.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP0KvwSnMoHy0ZCaOYcnQ9D",
   "mount_file_id": "1PrAXxmA2MYZKlBQVlgCytyYV5A4n4Ld4",
   "name": "LSTM_Klim_exogenous_ws",
   "provenance": [
    {
     "file_id": "1dOYMEJvLjV3jBfuQdVPDfvzyeOjrx6ub",
     "timestamp": 1634930860509
    },
    {
     "file_id": "1lblmzytM6D9w0hu4bReCIZGRMwXkI5Bi",
     "timestamp": 1634693283652
    },
    {
     "file_id": "1nqTIfFs3z9Ss2GaFAdi8jmUjbmzcB0PJ",
     "timestamp": 1634653625068
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
