{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Klim_exogenous_with_direction_and_T",
      "provenance": [],
      "mount_file_id": "1g3J8XPzeyxSAemmcZE6s-l12PVHfagfY",
      "authorship_tag": "ABX9TyNLkiC/Cfd+44KU4laYj28r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s192624/WindPower_forecasting_Klim/blob/main/LSTM_Klim_exogenous_with_direction_and_T.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emAUeLserWhf"
      },
      "source": [
        "**Forecast of power 3 hours ahead based on LSTM with knowledge of wind speed, wind direction and temperature - with use of 7 days slices**\n",
        "\n",
        "As a first step, an LSTM network is implemented considering only the power time series. The results can be compared with those of the AR(4) model fitted to the data in Matlab: 95% confidence intervals:\n",
        "\n",
        "*   1h ahead: [-3.17:3.17]\n",
        "*   2h ahead: [-4.73:4.73]\n",
        "*   3h ahead: [-5.76:5.76]\n",
        "\n",
        "And the LSTM network with slices:\n",
        "\n",
        "*   1h ahead: [-3.12:3.12]\n",
        "*   2h ahead: [-4.67:4.67]\n",
        "*   3h ahead: [-5.72:5.72]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P9gAZGSs4P5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import statistics as stat\n",
        "from random import shuffle\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w8xacq6sY78"
      },
      "source": [
        "# Load the data and extract colums\n",
        "file = '/content/drive/MyDrive/Colab Notebooks/Time series/LSTM_Klim/cex4WindDataInterpolated.csv'\n",
        "data = pd.read_csv(file)\n",
        "t = data.iloc[:,0].values\n",
        "p = data.iloc[:,2].values\n",
        "ws1 = data.iloc[:,3].values\n",
        "ws2 = data.iloc[:,6].values\n",
        "ws3 = data.iloc[:,9].values\n",
        "wd1 = data.iloc[:,4].values\n",
        "wd2 = data.iloc[:,7].values\n",
        "wd3 = data.iloc[:,10].values\n",
        "T1 = data.iloc[:,5].values\n",
        "T2 = data.iloc[:,8].values\n",
        "T3 = data.iloc[:,11].values"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyKfLbmroUv0"
      },
      "source": [
        "# Normalize the data except wind direction which will be one hot encoded\n",
        "p_mean = np.nanmean(p)\n",
        "p_std = np.nanstd(p)\n",
        "ws_mean = np.nanmean(ws1)\n",
        "ws_std = np.nanstd(ws1)\n",
        "T_mean = np.nanmean(T1)\n",
        "T_std = np.nanstd(T1)\n",
        "\n",
        "p = (p-p_mean)/p_std\n",
        "ws1 = (ws1-ws_mean)/ws_std\n",
        "ws2 = (ws2-ws_mean)/ws_std\n",
        "ws3 = (ws3-ws_mean)/ws_std\n",
        "T1 = (T1-T_mean)/T_std\n",
        "T2 = (T2-T_mean)/T_std\n",
        "T3 = (T3-T_mean)/T_std"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMnS5eeJI9U8"
      },
      "source": [
        "# Loop to keep sequences of valid power, wind speed and wind direction\n",
        "p_valid, ws1_valid, ws2_valid, ws3_valid, wd1_valid, wd2_valid, wd3_valid  = [],[],[],[],[],[],[]\n",
        "T1_valid, T2_valid, T3_valid = [],[],[]\n",
        "current_seq_p, current_seq_ws1, current_seq_ws2 , current_seq_ws3,  = [],[],[],[]\n",
        "current_seq_wd1, current_seq_wd2 , current_seq_wd3, current_seq_T1, current_seq_T2 , current_seq_T3 = [],[],[],[],[],[] \n",
        "\n",
        "nan = 1             # 1 if former value is nan\n",
        "\n",
        "for i in range(len(p)):\n",
        "\n",
        "  # Check if current value is nan\n",
        "  if np.isnan(p[i]) or np.isnan(ws1[i]) or np.isnan(wd1[i]) or np.isnan(T1[i]):\n",
        "    # If former value not nan, store former sequence and create a new one \n",
        "    if nan == 0:\n",
        "      p_valid.append(current_seq_p)\n",
        "      ws1_valid.append(current_seq_ws1)\n",
        "      ws2_valid.append(current_seq_ws2)\n",
        "      ws3_valid.append(current_seq_ws3)\n",
        "      wd1_valid.append(current_seq_wd1)\n",
        "      wd2_valid.append(current_seq_wd2)\n",
        "      wd3_valid.append(current_seq_wd3)\n",
        "      T1_valid.append(current_seq_T1)\n",
        "      T2_valid.append(current_seq_T2)\n",
        "      T3_valid.append(current_seq_T3)\n",
        "      current_seq_p, current_seq_ws1, current_seq_ws2 , current_seq_ws3,  = [],[],[],[]\n",
        "      current_seq_wd1, current_seq_wd2 , current_seq_wd3, current_seq_T1, current_seq_T2 , current_seq_T3 = [],[],[],[],[],[] \n",
        "    nan = 1\n",
        "\n",
        "  # Else, store the value and state it is not nan\n",
        "  else:\n",
        "    current_seq_p.append([p[i]])\n",
        "    current_seq_ws1.append([ws1[i]])\n",
        "    current_seq_ws2.append([ws2[i]])\n",
        "    current_seq_ws3.append([ws3[i]])\n",
        "    current_seq_wd1.append([wd1[i]])\n",
        "    current_seq_wd2.append([wd2[i]])\n",
        "    current_seq_wd3.append([wd3[i]])\n",
        "    current_seq_T1.append([T1[i]])\n",
        "    current_seq_T2.append([T2[i]])\n",
        "    current_seq_T3.append([T3[i]])\n",
        "    nan = 0\n",
        "\n",
        "p_valid.append(current_seq_p)\n",
        "ws1_valid.append(current_seq_ws1)\n",
        "ws2_valid.append(current_seq_ws2)\n",
        "ws3_valid.append(current_seq_ws3)\n",
        "wd1_valid.append(current_seq_wd1)\n",
        "wd2_valid.append(current_seq_wd2)\n",
        "wd3_valid.append(current_seq_wd3)\n",
        "T1_valid.append(current_seq_T1)\n",
        "T2_valid.append(current_seq_T2)\n",
        "T3_valid.append(current_seq_T3)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw_hS6vctl9s"
      },
      "source": [
        "# Define slices of 168h power inputs and corresponding targets one 1h ahead\n",
        "# Also define forecasts of wind speed, wind direction and temperature\n",
        "p_inputs, p_targets, p_targets2h, p_targets3h = [],[],[],[]\n",
        "ws1_forecast, ws2_forecast, ws3_forecast = [],[],[]\n",
        "wd1_forecast, wd2_forecast, wd3_forecast = [],[],[]\n",
        "T1_forecast, T2_forecast, T3_forecast = [],[],[]\n",
        "\n",
        "for seq in range(len(p_valid)):\n",
        "  for i in range(len(p_valid[seq])-170):\n",
        "    p_inputs.append(p_valid[seq][i:i+168])\n",
        "    p_targets.append(p_valid[seq][i+168])\n",
        "    p_targets2h.append(p_valid[seq][i+169])\n",
        "    p_targets3h.append(p_valid[seq][i+170])\n",
        "    ws1_forecast.append(ws1_valid[seq][i+168])\n",
        "    ws2_forecast.append(ws2_valid[seq][i+168])\n",
        "    ws3_forecast.append(ws3_valid[seq][i+168])\n",
        "    wd1_forecast.append(wd1_valid[seq][i+168])\n",
        "    wd2_forecast.append(wd2_valid[seq][i+168])\n",
        "    wd3_forecast.append(wd3_valid[seq][i+168])\n",
        "    T1_forecast.append(T1_valid[seq][i+168])\n",
        "    T2_forecast.append(T2_valid[seq][i+168])\n",
        "    T3_forecast.append(T3_valid[seq][i+168])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HmTmwl64sTT"
      },
      "source": [
        "# One hot encode the wind directions\n",
        "wd1_forecast_onehot = []\n",
        "wd2_forecast_onehot = []\n",
        "wd3_forecast_onehot = []\n",
        "\n",
        "# For wd1\n",
        "for i in range(len(wd1_forecast)):\n",
        "  onehot = 12*[None]\n",
        "  sector = np.floor(wd1_forecast[i][0]/30)\n",
        "  for s in range(12):\n",
        "    if sector == s:\n",
        "      onehot[s] = 1\n",
        "    else:\n",
        "      onehot[s] = 0\n",
        "  wd1_forecast_onehot.append(onehot)\n",
        "\n",
        "# For wd2\n",
        "for i in range(len(wd2_forecast)):\n",
        "  onehot = 12*[None]\n",
        "  sector = np.floor(wd2_forecast[i][0]/30)\n",
        "  for s in range(12):\n",
        "    if sector == s:\n",
        "      onehot[s] = 1\n",
        "    else:\n",
        "      onehot[s] = 0\n",
        "  wd2_forecast_onehot.append(onehot)\n",
        "\n",
        "# For wd3\n",
        "for i in range(len(wd3_forecast)):\n",
        "  onehot = 12*[None]\n",
        "  sector = np.floor(wd3_forecast[i][0]/30)\n",
        "  for s in range(12):\n",
        "    if sector == s:\n",
        "      onehot[s] = 1\n",
        "    else:\n",
        "      onehot[s] = 0\n",
        "  wd3_forecast_onehot.append(onehot) "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5VG0FGhWI4d"
      },
      "source": [
        "# Shuffle the inputs and targets\n",
        "l = list(zip(p_inputs,p_targets,p_targets2h,p_targets3h,ws1_forecast,ws2_forecast,ws3_forecast,\n",
        "             wd1_forecast,wd2_forecast,wd3_forecast,T1_forecast,T2_forecast,T3_forecast))\n",
        "shuffle(l)\n",
        "p_inputs,p_targets,p_targets2h,p_targets3h,ws1_forecast,ws2_forecast,ws3_forecast,wd1_forecast,wd2_forecast,wd3_forecast,T1_forecast,T2_forecast,T3_forecast = zip(*l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfOhAEu0xVTr",
        "outputId": "a1d065bd-51bd-4b4f-ffca-3794e395ead6"
      },
      "source": [
        "# Define an LSTM network\n",
        "\n",
        "class MyRecurrentNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyRecurrentNet, self).__init__()\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size =1,hidden_size=128, batch_first = False)        \n",
        "        self.ffnn_forecast1 = nn.Linear(in_features = 14, out_features = 512, bias = False)\n",
        "        self.ffnn_forecast2 = nn.Linear(in_features = 512, out_features = 512, bias = False)\n",
        "        \n",
        "        # Output layer\n",
        "        self.l_out = nn.Linear(in_features=512+128,\n",
        "                            out_features=1,\n",
        "                            bias=False)\n",
        "        \n",
        "    def forward(self, p_past, ws_forecast, wd_forecast, T_forecast):\n",
        "\n",
        "        # RNN returns output\n",
        "        x_rnn, (h, c) = self.lstm(p_past)\n",
        "        \n",
        "        # FNN on the wind speed forecast\n",
        "        x_ffnn = elu(self.ffnn_forecast1(torch.cat((ws_forecast,wd_forecast,T_forecast),1))) # Concatenate on dim 1, being the features, 0 is the batch samples\n",
        "        x_ffnn = elu(self.ffnn_forecast2(x_ffnn))\n",
        "\n",
        "        # Output layer on the concatenate last rnn hidden state and ffnn result\n",
        "        x = torch.cat((x_rnn[-1], x_ffnn), 1)  # Concatenate on dimension 1, 0 being the batch samples, 1 being the units\n",
        "        x = self.l_out(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "net = MyRecurrentNet()\n",
        "print(net)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyRecurrentNet(\n",
            "  (lstm): LSTM(1, 128)\n",
            "  (ffnn_forecast1): Linear(in_features=14, out_features=512, bias=False)\n",
            "  (ffnn_forecast2): Linear(in_features=512, out_features=512, bias=False)\n",
            "  (l_out): Linear(in_features=640, out_features=1, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KSR0vFRFTn_"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-M5ODoozyR-",
        "outputId": "f4dcf599-e4be-4d1f-e8b7-059cf6684a89"
      },
      "source": [
        "# Test of a dummy input of two sequences\n",
        "dummy = torch.tensor(list([\n",
        "                                [[1.0],[2.0],[3.0]],\n",
        "                                [[4.0],[5.0],[6.0]]\n",
        "                    ])).float()\n",
        "dummy = torch.swapaxes(dummy,0,1) # The network uses the format (Seq, Batch, Features)\n",
        "forecast_ws = torch.tensor([[1.0],[2.0]]).float()\n",
        "forecast_wd = torch.tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).float()\n",
        "forecast_T = torch.tensor([[270],[300]]).float()\n",
        "net(dummy,forecast_ws,forecast_wd,forecast_T)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 9.3702],\n",
              "        [10.4224]], grad_fn=<MmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYXiSNGTRHLj",
        "outputId": "41bc39f1-aecf-4ea5-e93a-38311a993464"
      },
      "source": [
        "# Test the untrained network on two first sequences\n",
        "net(torch.swapaxes(torch.Tensor([p_inputs[0],p_inputs[1]]),0,1),\n",
        "    torch.Tensor([ws1_forecast[0],ws1_forecast[1]]),\n",
        "    torch.Tensor([wd1_forecast_onehot[0],wd1_forecast_onehot[1]]),\n",
        "    torch.Tensor([T1_forecast[0],T1_forecast[1]]),\n",
        "    )"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0532],\n",
              "        [-0.0532]], grad_fn=<MmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK-WIrQw3oXy"
      },
      "source": [
        "# Initialize the network\n",
        "net = MyRecurrentNet()\n",
        "# Convert to cuda if GPU available\n",
        "if torch.cuda.is_available():\n",
        "    print('##converting network to cuda-enabled')\n",
        "    net.cuda()\n",
        "\n",
        "# Define loss function and train parameters\n",
        "criterion = nn.MSELoss(reduction='sum')    # Sum the squares but not perform the mean\n",
        "\n",
        "# Adam gradient descent with learning rate decay\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
        "decayRate = 0.999\n",
        "decay_scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
        "\n",
        "# Length of the training and batches\n",
        "epochs = 40\n",
        "batch_size = 32\n",
        "num_batch = len(p_inputs)//batch_size\n",
        "\n",
        "# Function to get the batch\n",
        "get_batch = lambda i, size: range(i * size, (i + 1) * size)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "id": "rwtnB57XBcfC",
        "outputId": "f6c7a92a-31f9-4690-cfdd-555fcde96912"
      },
      "source": [
        "# Training\n",
        "\n",
        "# Track loss\n",
        "training_RMSE = []\n",
        "\n",
        "# Loop over epochs\n",
        "for i in range(epochs):\n",
        "\n",
        "    epoch_training_loss = 0\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    # For each sequence in training set\n",
        "    for b in range(num_batch):\n",
        "\n",
        "      batch_index = get_batch(b,batch_size)\n",
        "                 \n",
        "      # Convert to tensor and swap axes of inputs to get (seq, batch, features)\n",
        "      inputs_past = torch.swapaxes(torch.Tensor(p_inputs)[batch_index],0,1)\n",
        "      inputs_forecast_ws = torch.Tensor(ws1_forecast)[batch_index]\n",
        "      inputs_forecast_wd = torch.Tensor(wd1_forecast_onehot)[batch_index]\n",
        "      inputs_forecast_T = torch.Tensor(T1_forecast)[batch_index]\n",
        "      targets = torch.Tensor(p_targets)[batch_index]\n",
        "\n",
        "      # Convert to cuda to run on GPU\n",
        "      if torch.cuda.is_available():\n",
        "            inputs_past = Variable(inputs_past.cuda())\n",
        "            inputs_forecast_ws = Variable(inputs_forecast_ws.cuda())\n",
        "            inputs_forecast_wd = Variable(inputs_forecast_wd.cuda())\n",
        "            inputs_forecast_T = Variable(inputs_forecast_T.cuda())\n",
        "            targets = Variable(targets.cuda())\n",
        "\n",
        "      # Forward pass\n",
        "      outputs = net(inputs_past,inputs_forecast_ws,inputs_forecast_wd,inputs_forecast_T)\n",
        "          \n",
        "      # Compute loss\n",
        "      loss = criterion(outputs, targets)\n",
        "          \n",
        "      # Backward pass\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "          \n",
        "      # Update loss\n",
        "      if torch.cuda.is_available():\n",
        "        epoch_training_loss += loss.cpu().detach().numpy()\n",
        "      else:\n",
        "        epoch_training_loss += loss.detach().numpy()\n",
        "    \n",
        "    # Save loss for plot\n",
        "    epoch_RMSE = np.sqrt(epoch_training_loss/(num_batch*batch_size))\n",
        "    training_RMSE.append(epoch_RMSE*p_std)  # Storing epoch RMSE and removing normalization to evaluate RMSE\n",
        "\n",
        "    # Compute confidence interval\n",
        "    CI = [norm.ppf(0.025)*training_RMSE[-1],norm.ppf(0.975)*training_RMSE[-1]]\n",
        "\n",
        "    # Print loss every 10 epochs\n",
        "    if i % 1 == 0:\n",
        "        print('Epoch %d, training RMSE: %.2f, CI: [%.2f:%.2f]' % (i+1,training_RMSE[-1],CI[0],CI[1]))\n",
        "\n",
        "    # Apply learning rate decay\n",
        "    decay_scheduler.step()\n",
        "\n",
        "# Plot training loss\n",
        "epoch = np.arange(len(training_RMSE))\n",
        "plt.figure()\n",
        "plt.plot(epoch, training_RMSE, 'r')\n",
        "plt.xlabel('Epoch'), plt.ylabel('Training RMSE')\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, training RMSE: 2.74, CI: [-5.37:5.37]\n",
            "Epoch 2, training RMSE: 1.99, CI: [-3.90:3.90]\n",
            "Epoch 3, training RMSE: 1.73, CI: [-3.40:3.40]\n",
            "Epoch 4, training RMSE: 1.62, CI: [-3.17:3.17]\n",
            "Epoch 5, training RMSE: 1.57, CI: [-3.07:3.07]\n",
            "Epoch 6, training RMSE: 1.55, CI: [-3.05:3.05]\n",
            "Epoch 7, training RMSE: 1.55, CI: [-3.03:3.03]\n",
            "Epoch 8, training RMSE: 1.54, CI: [-3.02:3.02]\n",
            "Epoch 9, training RMSE: 1.54, CI: [-3.01:3.01]\n",
            "Epoch 10, training RMSE: 1.53, CI: [-3.01:3.01]\n",
            "Epoch 11, training RMSE: 1.53, CI: [-3.00:3.00]\n",
            "Epoch 12, training RMSE: 1.53, CI: [-3.00:3.00]\n",
            "Epoch 13, training RMSE: 1.53, CI: [-3.00:3.00]\n",
            "Epoch 14, training RMSE: 1.53, CI: [-2.99:2.99]\n",
            "Epoch 15, training RMSE: 1.53, CI: [-2.99:2.99]\n",
            "Epoch 16, training RMSE: 1.52, CI: [-2.99:2.99]\n",
            "Epoch 17, training RMSE: 1.52, CI: [-2.99:2.99]\n",
            "Epoch 18, training RMSE: 1.52, CI: [-2.98:2.98]\n",
            "Epoch 19, training RMSE: 1.52, CI: [-2.98:2.98]\n",
            "Epoch 20, training RMSE: 1.52, CI: [-2.98:2.98]\n",
            "Epoch 21, training RMSE: 1.52, CI: [-2.98:2.98]\n",
            "Epoch 22, training RMSE: 1.52, CI: [-2.98:2.98]\n",
            "Epoch 23, training RMSE: 1.52, CI: [-2.98:2.98]\n",
            "Epoch 24, training RMSE: 1.52, CI: [-2.97:2.97]\n",
            "Epoch 25, training RMSE: 1.52, CI: [-2.97:2.97]\n",
            "Epoch 26, training RMSE: 1.52, CI: [-2.97:2.97]\n",
            "Epoch 27, training RMSE: 1.52, CI: [-2.97:2.97]\n",
            "Epoch 28, training RMSE: 1.52, CI: [-2.97:2.97]\n",
            "Epoch 29, training RMSE: 1.51, CI: [-2.97:2.97]\n",
            "Epoch 30, training RMSE: 1.51, CI: [-2.97:2.97]\n",
            "Epoch 31, training RMSE: 1.51, CI: [-2.97:2.97]\n",
            "Epoch 32, training RMSE: 1.51, CI: [-2.97:2.97]\n",
            "Epoch 33, training RMSE: 1.51, CI: [-2.97:2.97]\n",
            "Epoch 34, training RMSE: 1.51, CI: [-2.97:2.97]\n",
            "Epoch 35, training RMSE: 1.51, CI: [-2.96:2.96]\n",
            "Epoch 36, training RMSE: 1.51, CI: [-2.96:2.96]\n",
            "Epoch 37, training RMSE: 1.51, CI: [-2.96:2.96]\n",
            "Epoch 38, training RMSE: 1.51, CI: [-2.96:2.96]\n",
            "Epoch 39, training RMSE: 1.51, CI: [-2.96:2.96]\n",
            "Epoch 40, training RMSE: 1.51, CI: [-2.96:2.96]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgeS4EEXXR_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85e6849-b32b-4fcb-d96a-65a682dfd9d9"
      },
      "source": [
        "# Forecasting 1, 2 and 3 hours ahead\n",
        "\n",
        "# Back on CPU\n",
        "net.to('cpu')\n",
        "\n",
        "# Store predictions and errors\n",
        "pred_1h = []\n",
        "err_1h = []\n",
        "pred_2h = []\n",
        "err_2h = []\n",
        "pred_3h = []\n",
        "err_3h = []\n",
        "\n",
        "# Loop over the sequences of valid data and ws forecast\n",
        "for seq in range(len(p_inputs)):\n",
        "\n",
        "    # Define past value for the 1h forecast\n",
        "    past = p_inputs[seq]\n",
        "    ws_forecast = ws1_forecast[seq]\n",
        "    wd_forecast = wd1_forecast_onehot[seq]\n",
        "    T_forecast = T1_forecast[seq]\n",
        "  \n",
        "    # Take output of first and only sequence, last value\n",
        "    pred_1h.append(net(torch.swapaxes(torch.Tensor([past]),0,1),torch.Tensor([ws_forecast]),torch.Tensor([wd_forecast]),torch.Tensor([T_forecast])).item())\n",
        "    err_1h.append(pred_1h[-1]-p_targets[seq][0])\n",
        "\n",
        "    # Repeat with prediction 2 hours ahead actualizing first the past values\n",
        "    past.append([pred_1h[-1]])\n",
        "    ws_forecast = ws2_forecast[seq+1]   #Take the forecast for 2h ahead (seq+1) made at least 2h before (ws2)\n",
        "    wd_forecast = wd2_forecast_onehot[seq+1]\n",
        "    T_forecast = T2_forecast[seq+1]\n",
        "    pred_2h.append(net(torch.swapaxes(torch.Tensor([past]),0,1),torch.Tensor([ws_forecast]),torch.Tensor([wd_forecast]),torch.Tensor([T_forecast])).item())\n",
        "    err_2h.append(pred_2h[-1]-p_targets2h[seq][0])\n",
        "\n",
        "    # Repeat with prediction 3 hours ahead\n",
        "    past.append([pred_2h[-1]])\n",
        "    ws_forecast = ws3_forecast[seq+2]\n",
        "    wd_forecast = wd3_forecast_onehot[seq+2]\n",
        "    T_forecast = T3_forecast[seq+2]\n",
        "    pred_3h.append(net(torch.swapaxes(torch.Tensor([past]),0,1),torch.Tensor([ws_forecast]),torch.Tensor([wd_forecast]),torch.Tensor([T_forecast])).item())\n",
        "    err_3h.append(pred_3h[-1]-p_targets3h[seq][0])\n",
        "\n",
        "    if seq % 1000 == 0:\n",
        "      print('progress %.2f %%, RMSE 1h: %.2f, RMSE 2h: %.2f, RMSE 3h: %.2f'\n",
        "           % (100*(seq+1)/len(p_inputs),\n",
        "            p_std*np.sqrt(stat.mean(err_1h[n]**2 for n in range(len(err_1h)))),\n",
        "            p_std*np.sqrt(stat.mean(err_2h[n]**2 for n in range(len(err_2h)))), \n",
        "            p_std*np.sqrt(stat.mean(err_3h[n]**2 for n in range(len(err_3h)))))\n",
        "           )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "progress 0.00 %, RMSE 1h: 0.35, RMSE 2h: 0.33, RMSE 3h: 0.34\n",
            "progress 2.87 %, RMSE 1h: 1.96, RMSE 2h: 2.71, RMSE 3h: 3.05\n",
            "progress 5.73 %, RMSE 1h: 1.79, RMSE 2h: 2.46, RMSE 3h: 2.79\n",
            "progress 8.59 %, RMSE 1h: 1.70, RMSE 2h: 2.42, RMSE 3h: 2.80\n",
            "progress 11.46 %, RMSE 1h: 1.66, RMSE 2h: 2.39, RMSE 3h: 2.77\n",
            "progress 14.32 %, RMSE 1h: 1.58, RMSE 2h: 2.26, RMSE 3h: 2.62\n",
            "progress 17.18 %, RMSE 1h: 1.51, RMSE 2h: 2.15, RMSE 3h: 2.48\n",
            "progress 20.04 %, RMSE 1h: 1.52, RMSE 2h: 2.18, RMSE 3h: 2.52\n",
            "progress 22.91 %, RMSE 1h: 1.61, RMSE 2h: 2.29, RMSE 3h: 2.63\n",
            "progress 25.77 %, RMSE 1h: 1.66, RMSE 2h: 2.36, RMSE 3h: 2.73\n",
            "progress 28.63 %, RMSE 1h: 1.67, RMSE 2h: 2.38, RMSE 3h: 2.75\n",
            "progress 31.50 %, RMSE 1h: 1.62, RMSE 2h: 2.32, RMSE 3h: 2.68\n",
            "progress 34.36 %, RMSE 1h: 1.62, RMSE 2h: 2.32, RMSE 3h: 2.69\n",
            "progress 37.22 %, RMSE 1h: 1.59, RMSE 2h: 2.28, RMSE 3h: 2.64\n",
            "progress 40.09 %, RMSE 1h: 1.58, RMSE 2h: 2.26, RMSE 3h: 2.62\n",
            "progress 42.95 %, RMSE 1h: 1.59, RMSE 2h: 2.27, RMSE 3h: 2.62\n",
            "progress 45.81 %, RMSE 1h: 1.59, RMSE 2h: 2.27, RMSE 3h: 2.62\n",
            "progress 48.68 %, RMSE 1h: 1.58, RMSE 2h: 2.26, RMSE 3h: 2.61\n",
            "progress 51.54 %, RMSE 1h: 1.58, RMSE 2h: 2.26, RMSE 3h: 2.60\n",
            "progress 54.40 %, RMSE 1h: 1.58, RMSE 2h: 2.25, RMSE 3h: 2.59\n",
            "progress 57.27 %, RMSE 1h: 1.57, RMSE 2h: 2.24, RMSE 3h: 2.59\n",
            "progress 60.13 %, RMSE 1h: 1.56, RMSE 2h: 2.23, RMSE 3h: 2.58\n",
            "progress 62.99 %, RMSE 1h: 1.55, RMSE 2h: 2.21, RMSE 3h: 2.56\n",
            "progress 65.85 %, RMSE 1h: 1.55, RMSE 2h: 2.21, RMSE 3h: 2.55\n",
            "progress 68.72 %, RMSE 1h: 1.54, RMSE 2h: 2.19, RMSE 3h: 2.54\n",
            "progress 71.58 %, RMSE 1h: 1.55, RMSE 2h: 2.21, RMSE 3h: 2.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IojzG9kMY1Y3"
      },
      "source": [
        "# Estimation of confidence intervals:\n",
        "RMSE_1h = np.sqrt(stat.mean(err_1h[n]**2 for n in range(len(err_1h))))\n",
        "RMSE_2h = np.sqrt(stat.mean(err_2h[n]**2 for n in range(len(err_2h))))\n",
        "RMSE_3h = np.sqrt(stat.mean(err_3h[n]**2 for n in range(len(err_3h))))\n",
        "CI_1h = [norm.ppf(0.025)*RMSE_1h,norm.ppf(0.975)*RMSE_1h]\n",
        "CI_2h = [norm.ppf(0.025)*RMSE_2h,norm.ppf(0.975)*RMSE_2h]\n",
        "CI_3h = [norm.ppf(0.025)*RMSE_3h,norm.ppf(0.975)*RMSE_3h]\n",
        "print(f'Confidence interval 1h: {CI_1h}')\n",
        "print(f'Confidence interval 2h: {CI_2h}')\n",
        "print(f'Confidence interval 3h: {CI_3h}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an1NIEcvaw03"
      },
      "source": [
        "# Save the model\n",
        "torch.save(net.state_dict(),\n",
        "           '/content/drive/MyDrive/Colab Notebooks/Time series/LSTM_Klim/LSTM_power_ws_wd_T.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}